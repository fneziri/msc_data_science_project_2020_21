# -*- coding: utf-8 -*-
"""MSc Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eZG8YPodEK5pLWRV1Qp_HGixRx1aV8Wu
"""

import pandas as pd
import numpy as np
import math

df = pd.read_json(path_or_buf='shots.json')

df = df.fillna(0)

df.shape
df.head()

df.count()

#create additional variable: shot distance

shot_distance = []

for i in range(0, df.shape[0]):
  x = df['location'][i][0]
  y = df['location'][i][1]
  distance = math.sqrt((120-x)**2 + (40-y)**2)
  shot_distance.append(distance)

df['shot_distance'] = shot_distance

#create additional variable: shot angle

shot_angle = []

for i in range(0, df.shape[0]):
  x = df['location'][i][0]
  y = df['location'][i][1]
  angle = math.degrees(math.atan((8*(120-x))/((120-x)**2 + ((y**2) - (80*y) + 1584))))
  shot_angle.append(angle)

df['shot_angle'] = shot_angle

#drop variables that we know aren't useful

df_trim = df.drop(['id', 'index','period','second','related_events','type.id','type.name',
                   'possession_team.id', 'possession_team.name', 'team.id', 'team.name',
                   'tactics.lineup', 'player.id',	'player.name', 'position.id',	'position.name',
                   'pass.end_location', 'carry.end_location',	'shot.statsbomb_xg', 'shot.end_location', 
                   'shot.key_pass_id', 'shot.freeze_frame', 'goalkeeper.end_location', 
                   'match_id', 'competition_id', 'season_id', 'out','off_camera', 'shot.saved_off_target', 
                   'shot.saved_to_post','shot.redirect'], axis=1)

df_trim.head()

#remove related variables columns e.g. id columns corresponding to name columns

df_clean = df_trim.drop(['timestamp','possession','location','play_pattern.id', 'play_pattern.name',
                         'shot.technique.id','shot.body_part.id','shot.type.id','shot.outcome.id'], axis =1)


#custom encoding for variables

df_clean['shot.body_part.name'] = ['Foot' if x in ['Right Foot', 'Left Foot'] else x for x in df_clean['shot.body_part.name']]
df_clean['shot.outcome.name'] = [1 if x == 'Goal' else 0 for x in df_clean['shot.outcome.name']]
df_clean = df_clean.rename(columns={'shot.outcome.name': 'goal'})

#one-hot encode variables

df_clean = pd.get_dummies(df_clean, columns=['shot.technique.name'])
df_clean = pd.get_dummies(df_clean, columns=['shot.body_part.name'])
df_clean = pd.get_dummies(df_clean, columns=['shot.type.name'])

df_clean.head()

#create X and Y dataframes

from sklearn.model_selection import train_test_split
from sklearn import preprocessing

X = df_clean.drop(['goal'], axis=1)
Y = df_clean['goal']

test_size = 0.33
seed = 7
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)


scaler = preprocessing.StandardScaler().fit(X_train)
x_train_scaled = scaler.transform(X_train)
x_test_scaled = scaler.transform(X_test)

columns = list(X)

X.head()

#feature selection using mutual information

from sklearn.feature_selection import mutual_info_classif

np.random.seed(7)

mi = mutual_info_classif(x_train_scaled,Y_train)
print("MI scores: ", mi)

mi_features = []
mi_index = []

for i in range(0,len(mi)):
  if mi[i] != 0:
    mi_features.append((columns[i]))
    mi_index.append(i)

x_train_mi = x_train_scaled[:, mi_index]
x_test_mi = x_test_scaled[:, mi_index]

print("Number of features after MI feature selection applied: ", len(mi_features))
print("Features selected after MI feature selection applied: ", mi_features)

df_clean_mi = df_clean[df_clean.columns.intersection(mi_features)]

df_clean_mi.head()

#feature selection using Recursive Feature Elimination (RFE)

from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestClassifier

np.random.seed(7)

rfecv = RFECV(estimator=RandomForestClassifier(),cv=5)
rfecv_fit = rfecv.fit(x_train_scaled,Y_train)

print("Number of features after RFE applied: ", rfecv_fit.n_features_)
print("RFE feature ranking: ", rfecv_fit.ranking_)
rfecv_fit.support_

rfe_features = []
rfe_index = []

for i in range(0,len(rfecv_fit.support_)):
  if rfecv_fit.support_[i] == True:
    rfe_features.append((columns[i]))
    rfe_index.append(i)

x_train_rfe = x_train_scaled[:, rfe_index]
x_test_rfe = x_test_scaled[:, rfe_index]

print("Features selected after RFE applied: ", rfe_features)

df_clean_rfe = df_clean[df_clean.columns.intersection(rfe_features)]

df_clean_rfe.head()

#feature selection using Feature Importance (Extra Trees Classifier)

from sklearn.ensemble import ExtraTreesClassifier

np.random.seed(7)

fi = ExtraTreesClassifier()
fi_fit = fi.fit(x_train_scaled,Y_train)

print("Feature importances: ", fi_fit.feature_importances_)

fi_features = []
fi_index = []

for i in range(0,fi_fit.n_features_):
  if fi_fit.feature_importances_[i] >= 0.003:
    fi_features.append((columns[i]))
    fi_index.append(i)

x_train_fi = x_train_scaled[:, fi_index]
x_test_fi = x_test_scaled[:, fi_index]

print("Number of features after FI feature selection applied: ", len(fi_features))
print("Features selected after FI feature selection applied: ", fi_features)

df_clean_fi = df_clean[df_clean.columns.intersection(fi_features)]

df_clean_fi.head()

#metrics to evaluate the different models

from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score


def evaluation_metrics(y_true,y_pred):
  print('Confusion Matrix: ','\n')
  print(confusion_matrix(y_true,y_pred),'\n')
  print('Accuracy: ', accuracy_score(y_true,y_pred))
  print('Recall: ', recall_score(y_true,y_pred))
  print('F1: ', f1_score(y_true,y_pred))
  print('Precision: ', precision_score(y_true,y_pred),'\n')

#models without tuning

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

np.random.seed(7)

def run_model(model, x_train, x_test, y_train, y_test):
  model.fit(x_train, y_train)
  y_pred = model.predict(x_test)
  print('ROC AUC: ', roc_auc_score(y_test, y_score=model.predict_proba(x_test)[:, 1]))
  evaluation_metrics(y_test, y_pred)

models = []
models.append(('Logistic Regression', LogisticRegression()))
models.append(('CART', DecisionTreeClassifier(random_state=7)))
models.append(('K-Nearest Neighbours', KNeighborsClassifier()))

x_data = []
x_data.append(('Feature Importance Dataset', x_train_fi, x_test_fi))
x_data.append(('Mutual Information Dataset', x_train_mi, x_test_mi))
x_data.append(('RFE Dataset', x_train_rfe, x_test_rfe))

for name, model in models:
  print(name,'\n')
  for x_name, x_train, x_test in x_data:
    print(x_name)
    run_model(model, x_train, x_test, Y_train, Y_test)

#create functions to tune hyperparameters

from scipy.stats import loguniform, randint
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

#grid search function

def grid_search(model,param_grid,x_train_data):
  gs = GridSearchCV(estimator=model,param_grid=param_grid,n_jobs=-1,scoring='roc_auc')
  gs_fit = gs.fit(x_train_data,Y_train)
  print(gs.best_params_)
  print(gs.best_score_)
  return gs_fit

param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100],
                 'penalty': ['l1', 'l2'],
                 'solver': ['liblinear', 'saga', 'lbfgs']
                 }

param_grid_cart = {'criterion':['gini','entropy'],
                   'max_features': ['auto', 'log2'],
                   'min_samples_split':np.arange(2,10),
                   'min_samples_leaf':np.arange(1,10)}              

param_grid_knn = {'n_neighbors': np.arange(1,10),
                  'metric': ['euclidean', 'manhattan', 'minkowski'],
                  'weights': ['uniform', 'distance']
                  }

#random search function

def random_search(model,param_dist,x_train_data):
  rs = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, random_state=7,n_jobs=-1,scoring='roc_auc')
  rs_fit = rs.fit(x_train_data,Y_train)
  print(rs.best_params_)
  print(rs.best_score_)
  return rs_fit

param_dist_lr = {'C': loguniform(0.01,100),
                 'penalty': ['l1', 'l2'],
                 'solver': ['liblinear', 'saga', 'lbfgs']
                 }

param_dist_cart = {'criterion':['gini','entropy'],
                   'max_features': ['auto', 'log2'],
                   'min_samples_split': randint(2,10),
                   'min_samples_leaf': randint(1,10)} 

param_dist_knn = {'n_neighbors': randint(1,10),
                  'metric': ['euclidean', 'manhattan', 'minkowski'],
                  'weights': ['uniform', 'distance']
                  }

param_all = []
param_all.append(('Logistic Regression', LogisticRegression(), param_grid_lr, param_dist_lr))
param_all.append(('CART', DecisionTreeClassifier(random_state=7), param_grid_cart, param_dist_cart))
param_all.append(('KNN', KNeighborsClassifier(), param_grid_knn, param_dist_knn))

#tune hyperparemeters

np.random.seed(7)

params_best = []

for name, model, param_grid, param_dist in param_all:
  print(name,'\n')
  for x_name, x_train, x_test in x_data:
    print(x_name)
    gs = grid_search(model, param_grid, x_train)
    rs = random_search(model, param_dist, x_train)
    if gs.best_score_ >= rs.best_score_:
      params_best.append((name, x_name, x_train, x_test, gs.best_estimator_))
    else:
      params_best.append((name, x_name, x_train, x_test, rs.best_estimator_))

#rerun models with tuned hyperparameters

from sklearn.metrics import roc_curve,plot_roc_curve
from matplotlib import pyplot as plt

np.random.seed(7)

for name, x_name, x_train, x_test, best_estimator in params_best:
  print(name,'\n')
  print(x_name,'\n')
  run_model(best_estimator, x_train, x_test, Y_train, Y_test)
  plot_roc_curve(best_estimator, x_test, Y_test)
  plt.show()